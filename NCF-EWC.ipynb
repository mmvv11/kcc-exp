{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"2\"  # Set the GPU 2 to use"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 무비렌즈"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# gpu 설정\n",
    "use_cuda = True\n",
    "\n",
    "use_cuda = use_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 데이터 준비"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "\n",
    "\"\"\"\n",
    "필요한 컬럼은 유저, 아이템, rating\n",
    "\n",
    "우선 간단하게 빨리 해보는게 중요하니,\n",
    "rating이 5점이면 rating 컬럼을 1\n",
    "아니라면 0로 바꾸자고.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def getDataByScenario(scenario):\n",
    "    \"\"\"\n",
    "    :param scenario: increase, fixed, user, item\n",
    "    :return: dfs\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "\n",
    "    if scenario in [\"increase\", 'fixed']:\n",
    "        for i in range(6):\n",
    "            df = pd.read_csv(f\"./dataset/Movielens/{scenario}/ml_1m_inc{i}.csv\")\n",
    "            dfs.append(df)\n",
    "\n",
    "    if scenario in [\"user\", \"item\"]:\n",
    "        for i in range(6):\n",
    "            train = pd.read_csv(f\"./dataset/Movielens/{scenario}/train_ml_1m_inc{i}.csv\")\n",
    "            test = pd.read_csv(f\"./dataset/Movielens/{scenario}/test_ml_1m_inc{i}.csv\")\n",
    "            dfs.append((train, test))\n",
    "\n",
    "    return dfs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## dataloader 정의"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MovielensDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = self.df.iloc[idx]['user']\n",
    "        item = self.df.iloc[idx]['item']\n",
    "        rating = self.df.iloc[idx]['rating']\n",
    "        return user, item, rating"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 정의"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# NCF 모델\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, emb_size=8, hidden_size=64):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, emb_size)\n",
    "        self.movie_embedding = nn.Embedding(n_movies, emb_size)\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(emb_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, user_input, movie_input):\n",
    "        user_embedded = self.user_embedding(user_input)\n",
    "        movie_embedded = self.movie_embedding(movie_input)\n",
    "        input_concat = torch.cat([user_embedded, movie_embedded], dim=-1)\n",
    "        prediction = self.fc_layers(input_concat)\n",
    "        return prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 train/test 함수 정의"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    train_loss = 0\n",
    "    for user, item, rating in train_loader:\n",
    "        user, item, rating = user.to(device), item.to(device), rating.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(user, item).squeeze()\n",
    "        loss = criterion(output, rating.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    # print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, train_loss))\n",
    "\n",
    "    return train_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recall_at_k(output, target, k):\n",
    "    if len(output) < k:\n",
    "        k = len(output)\n",
    "    _, idx = torch.topk(output, k=k)\n",
    "    hit = torch.sum(target[idx])\n",
    "    return hit.float() / target.sum().float() if target.sum().float() else torch.Tensor([0])\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, k=20):\n",
    "    model.eval()\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    test_loss = 0\n",
    "    test_recall = 0\n",
    "    with torch.no_grad():\n",
    "        for user, item, rating in test_loader:\n",
    "            user, item, rating = user.to(device), item.to(device), rating.to(device)\n",
    "            output = model(user, item).squeeze()\n",
    "            loss = criterion(output, rating.float())\n",
    "            test_loss += loss.item()\n",
    "            test_recall += recall_at_k(output, rating, k).item()  # recall@20 기준\n",
    "    test_loss /= len(test_loader)\n",
    "    test_recall /= len(test_loader)\n",
    "\n",
    "    return test_loss, test_recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 모델 학습\n",
    "\n",
    "0. Full\n",
    "1. Naive\n",
    "2. EWC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Config..\n",
    "EPOCH = 1\n",
    "SEED = 42\n",
    "BATCH_SIZE = 64\n",
    "N_USER = 6040\n",
    "N_ITEM = 3952"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "0. Full"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def concat_df(dfs, k):\n",
    "    return pd.concat(dfs[:k+1], axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getFullResultByScenario(scenario):\n",
    "    recall_list = []\n",
    "    dfs = getDataByScenario(scenario)\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "        # 모델 객체 생성\n",
    "        n_users = N_USER + 1\n",
    "        n_movies = N_ITEM + 1\n",
    "        model = NCF(n_users, n_movies).to(device)\n",
    "        # 옵티마이저 설정\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        if i == 0:\n",
    "            # base block train-test\n",
    "            if scenario in [\"increase\", \"fixed\"]:\n",
    "                train_dataset, test_dataset = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "            elif scenario in [\"user\", \"item\"]:\n",
    "                train_dataset, test_dataset = df\n",
    "\n",
    "            train_dataset = MovielensDataset(train_dataset)\n",
    "            test_dataset = MovielensDataset(test_dataset)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "            # train\n",
    "            epoch = EPOCH\n",
    "            # print(f\"************** Train Start At TASK{i}\")\n",
    "            for e in tqdm(range(1, epoch + 1)):\n",
    "                train(model, device, train_loader, optimizer, e)\n",
    "\n",
    "            # test\n",
    "            _, recall20 = test(model, device, test_loader)\n",
    "            recall_list.append(recall20)\n",
    "            print(f\"******* {scenario} scenario At {i} TASK recall20 = {recall20}\")\n",
    "\n",
    "        else:\n",
    "            # inc block train-test\n",
    "            if scenario in [\"increase\", \"fixed\"]:\n",
    "                #\n",
    "                if i == len(dfs)-1:\n",
    "                    break\n",
    "                # train dataset은 0~i를 모두 concat한 것\n",
    "                train_dataset = concat_df(dfs, i)\n",
    "                test_dataset = dfs[i+1]\n",
    "\n",
    "            elif scenario in [\"user\", \"item\"]:\n",
    "                temp_dfs =  []\n",
    "                for j in range(i):\n",
    "                    temp_dfs.append(dfs[j][0])\n",
    "                train_dataset = concat_df(temp_dfs, i)\n",
    "                _, test_dataset = df\n",
    "\n",
    "            train_dataset = MovielensDataset(train_dataset)\n",
    "            test_dataset = MovielensDataset(test_dataset)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "            # train\n",
    "            epoch = EPOCH\n",
    "            # print(f\"************** Train Start At TASK{i}\")\n",
    "            for e in tqdm(range(1, epoch + 1)):\n",
    "                train(model, device, train_loader, optimizer, e)\n",
    "\n",
    "            # test\n",
    "            _, recall20 = test(model, device, test_loader)\n",
    "            recall_list.append(recall20)\n",
    "            print(f\"******* {scenario} scenario At {i} TASK recall20 = {recall20}\")\n",
    "\n",
    "            # test\n",
    "            \"\"\"\n",
    "            user or item 시나리오의 경우,\n",
    "            현재 모델에 대해서,\n",
    "            이전 test 데이터들의 recall@20,\n",
    "            현재 test 데이터에 대한 recall@20\n",
    "            그리고 그 값에 대한 평균을 구해야 한다.\n",
    "            \"\"\"\n",
    "            if scenario in [\"user\", \"item\"]:\n",
    "                recall20_prev = []\n",
    "                for j in range(i+1):\n",
    "                    _, test_dataset = dfs[j]\n",
    "                    test_dataset = MovielensDataset(test_dataset)\n",
    "                    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "                    _, recall20 = test(model, device, test_loader)\n",
    "                    recall20_prev.append(recall20)\n",
    "                    print(f\"----- {scenario} scenario, when Task is {i}, prev Task {j} recall 20 = {recall20}\")\n",
    "                avg_prev_recall = sum(recall20_prev) / len(recall20_prev)\n",
    "                print(f\"{scenario} scenario avg prev recall : {avg_prev_recall}\")\n",
    "\n",
    "    avg_recall = sum(recall_list) / len(recall_list)\n",
    "    print(f\"{scenario} scenario avg recall : {avg_recall}\")\n",
    "    if scenario in [\"user\", \"item\"]:\n",
    "        return  (avg_recall, avg_prev_recall)\n",
    "    return avg_recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fullIncrease = getFullResultByScenario(\"increase\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fullFixed = getFullResultByScenario(\"fixed\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fullUser1, fullUser2 = getFullResultByScenario(\"user\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fullItem1, fullItem2 = getFullResultByScenario(\"item\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Naive"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "우선 모든 데이터에 대해 incremental training을 하고 test해보자"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getNaiveResultByScenario(scenario):\n",
    "    recall_list = []\n",
    "    dfs = getDataByScenario(scenario)\n",
    "    # 모델 객체 생성\n",
    "    n_users = N_USER + 1\n",
    "    n_movies = N_ITEM + 1\n",
    "    model = NCF(n_users, n_movies).to(device)\n",
    "    # 옵티마이저 설정\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "\n",
    "        if i == 0:\n",
    "            # base block train-test\n",
    "\n",
    "            if scenario in [\"increase\", \"fixed\"]:\n",
    "                train_dataset, test_dataset = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "            elif scenario in [\"user\", \"item\"]:\n",
    "                train_dataset, test_dataset = df\n",
    "\n",
    "            train_dataset = MovielensDataset(train_dataset)\n",
    "            test_dataset = MovielensDataset(test_dataset)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "            # train\n",
    "            epoch = EPOCH\n",
    "            # print(f\"************** Train Start At TASK{i}\")\n",
    "            for e in tqdm(range(1, epoch + 1)):\n",
    "                train(model, device, train_loader, optimizer, e)\n",
    "\n",
    "            # test\n",
    "            _, recall20 = test(model, device, test_loader)\n",
    "            recall_list.append(recall20)\n",
    "            print(f\"******* {scenario} scenario At {i} TASK recall20 = {recall20}\")\n",
    "\n",
    "        else:\n",
    "            # inc block train-test\n",
    "            # 모든 시나리오 마지막은 생략한다..\n",
    "            # if i == len(dfs)-1:\n",
    "            #         break\n",
    "\n",
    "            # 데이터 준비\n",
    "            if scenario in [\"increase\", \"fixed\"]:\n",
    "                #\n",
    "                if i == len(dfs)-1:\n",
    "                    break\n",
    "                train_dataset = df\n",
    "                test_dataset = dfs[i+1]\n",
    "            elif scenario in [\"user\", \"item\"]:\n",
    "                train_dataset, test_dataset = df\n",
    "\n",
    "            train_dataset = MovielensDataset(train_dataset)\n",
    "            test_dataset = MovielensDataset(test_dataset)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "            # train\n",
    "            epoch = EPOCH\n",
    "            # print(f\"************** Train Start At TASK{i}\")\n",
    "            for e in tqdm(range(1, epoch + 1)):\n",
    "                train(model, device, train_loader, optimizer, e)\n",
    "\n",
    "            # test\n",
    "            _, recall20 = test(model, device, test_loader)\n",
    "            recall_list.append(recall20)\n",
    "            print(f\"******* {scenario} scenario At {i} TASK recall20 = {recall20}\")\n",
    "\n",
    "            # test\n",
    "            \"\"\"\n",
    "            user or item 시나리오의 경우,\n",
    "            현재 모델에 대해서,\n",
    "            이전 test 데이터들의 recall@20,\n",
    "            현재 test 데이터에 대한 recall@20\n",
    "            그리고 그 값에 대한 평균을 구해야 한다.\n",
    "            \"\"\"\n",
    "            if scenario in [\"user\", \"item\"]:\n",
    "                recall20_prev = []\n",
    "                for j in range(i+1):\n",
    "                    _, test_dataset = dfs[j]\n",
    "                    test_dataset = MovielensDataset(test_dataset)\n",
    "                    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "                    _, recall20 = test(model, device, test_loader)\n",
    "                    recall20_prev.append(recall20)\n",
    "                    print(f\"----- {scenario} scenario, when Task is {i}, prev Task {j} recall 20 = {recall20}\")\n",
    "                avg_prev_recall = sum(recall20_prev) / len(recall20_prev)\n",
    "                print(f\"{scenario} scenario avg prev recall : {avg_prev_recall}\")\n",
    "\n",
    "    avg_recall = sum(recall_list) / len(recall_list)\n",
    "    print(f\"{scenario} scenario avg recall : {avg_recall}\")\n",
    "    if scenario in [\"user\", \"item\"]:\n",
    "        return  (avg_recall, avg_prev_recall)\n",
    "    return avg_recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "naiveIncrease = getNaiveResultByScenario(\"increase\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "naivefixed = getNaiveResultByScenario(\"fixed\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "naiveUser1, naiveUser2 = getNaiveResultByScenario(\"user\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "naiveItem1, naiveItem2 = getNaiveResultByScenario(\"item\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. EWC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Task가 끝날 때 마다 optpar와 fisher를 저장해주는 함수.\n",
    "def on_task_update(model, device, train_loader, optimizer, task_id, fisher_dict, optpar_dict):\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # accumulating gradients\n",
    "    for user, item, rating in train_loader:\n",
    "        user, item, rating = user.to(device), item.to(device), rating.to(device)\n",
    "        output = model(user, item).squeeze()\n",
    "        loss = criterion(output, rating.float())\n",
    "        loss.backward()\n",
    "\n",
    "    fisher_dict[task_id] = {}\n",
    "    optpar_dict[task_id] = {}\n",
    "\n",
    "    # gradients accumulated can be used to calculate fisher\n",
    "    for name, param in model.named_parameters():\n",
    "        fisher_dict[task_id][name] = param.grad.data.clone().pow(2)  # 누적 grad 값\n",
    "        optpar_dict[task_id][name] = param.data.clone()  # 최적 grad 값"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# EWC를 적용한 train 함수\n",
    "def train_ewc(model, device, train_loader, optimizer, epoch, task_id, fisher_dict, optpar_dict, ewc_lambda):\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    train_loss = 0\n",
    "    for user, item, rating in train_loader:\n",
    "        user, item, rating = user.to(device), item.to(device), rating.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(user, item).squeeze()\n",
    "        loss = criterion(output, rating.float())\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # EWC 적용 부분\n",
    "        for task in range(task_id):\n",
    "            for name, param in model.named_parameters():\n",
    "                fisher = fisher_dict[task][name]\n",
    "                optpar = optpar_dict[task][name]\n",
    "                train_loss += (fisher * (optpar - param).pow(2)).sum() * ewc_lambda\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    # print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, train_loss))\n",
    "\n",
    "    return train_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getEWCResultByScenario(scenario):\n",
    "    recall_list = []\n",
    "    dfs = getDataByScenario(scenario)\n",
    "\n",
    "    # 모델 객체 생성\n",
    "    n_users = N_USER + 1\n",
    "    n_movies = N_ITEM + 1\n",
    "    model = NCF(n_users, n_movies).to(device)\n",
    "    # 옵티마이저 설정\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # EWC에 필요한 변수\n",
    "    fisher_dict = {}\n",
    "    optpar_dict = {}\n",
    "    ewc_lambda = 0.4  # ewc 강도 조절.. 높을수록 이전 파라미터의 중요도가 높아짐\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "        if i == 0:\n",
    "            # base block train-test\n",
    "\n",
    "            if scenario in [\"increase\", \"fixed\"]:\n",
    "                train_dataset, test_dataset = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "            elif scenario in [\"user\", \"item\"]:\n",
    "                train_dataset, test_dataset = df\n",
    "\n",
    "            train_dataset = MovielensDataset(train_dataset)\n",
    "            test_dataset = MovielensDataset(test_dataset)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "            # train\n",
    "            epoch = EPOCH\n",
    "            # print(f\"************** Train Start At TASK{i}\")\n",
    "            for e in tqdm(range(1, epoch + 1)):\n",
    "                train_ewc(model, device, train_loader, optimizer, e, i, fisher_dict, optpar_dict, ewc_lambda)\n",
    "            on_task_update(model, device, train_loader, optimizer, i, fisher_dict, optpar_dict)\n",
    "\n",
    "            # test\n",
    "            _, recall20 = test(model, device, test_loader)\n",
    "            recall_list.append(recall20)\n",
    "            print(f\"******* {scenario} scenario At {i} TASK recall20 = {recall20}\")\n",
    "\n",
    "        else:\n",
    "            # inc block train-test\n",
    "\n",
    "            # 마지막은 생략한다..\n",
    "            # if i == len(dfs)-1:\n",
    "            #         break\n",
    "\n",
    "            # 데이터 준비\n",
    "            if scenario in [\"increase\", \"fixed\"]:\n",
    "                if i == len(dfs)-1:\n",
    "                    break\n",
    "                train_dataset = df\n",
    "                test_dataset = dfs[i+1]\n",
    "            elif scenario in [\"user\", \"item\"]:\n",
    "                train_dataset, test_dataset = df\n",
    "\n",
    "            train_dataset = MovielensDataset(train_dataset)\n",
    "            test_dataset = MovielensDataset(test_dataset)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "            # train\n",
    "            epoch = EPOCH\n",
    "            # print(f\"************** Train Start At TASK{i}\")\n",
    "            for e in tqdm(range(1, epoch + 1)):\n",
    "                train_ewc(model, device, train_loader, optimizer, e, i, fisher_dict, optpar_dict, ewc_lambda)\n",
    "            on_task_update(model, device, train_loader, optimizer, i, fisher_dict, optpar_dict)\n",
    "\n",
    "            # test\n",
    "            _, recall20 = test(model, device, test_loader)\n",
    "            recall_list.append(recall20)\n",
    "            print(f\"******* {scenario} scenario At {i} TASK recall20 = {recall20}\")\n",
    "\n",
    "            # test\n",
    "            \"\"\"\n",
    "            user or item 시나리오의 경우,\n",
    "            현재 모델에 대해서,\n",
    "            이전 test 데이터들의 recall@20,\n",
    "            현재 test 데이터에 대한 recall@20\n",
    "            그리고 그 값에 대한 평균을 구해야 한다.\n",
    "            \"\"\"\n",
    "            if scenario in [\"user\", \"item\"]:\n",
    "                recall20_prev = []\n",
    "                for j in range(i+1):\n",
    "                    _, test_dataset = dfs[j]\n",
    "                    test_dataset = MovielensDataset(test_dataset)\n",
    "                    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "                    _, recall20 = test(model, device, test_loader)\n",
    "                    recall20_prev.append(recall20)\n",
    "                    print(f\"----- {scenario} scenario, when Task is {i}, prev Task {j} recall 20 = {recall20}\")\n",
    "                avg_prev_recall = sum(recall20_prev) / len(recall20_prev)\n",
    "                print(f\"{scenario} scenario avg prev recall : {avg_prev_recall}\")\n",
    "\n",
    "    avg_recall = sum(recall_list) / len(recall_list)\n",
    "    print(f\"{scenario} scenario avg recall : {avg_recall}\")\n",
    "    if scenario in [\"user\", \"item\"]:\n",
    "        return  (avg_recall, avg_prev_recall)\n",
    "    return avg_recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ewcIncrease = getEWCResultByScenario(\"increase\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ewcfixed = getEWCResultByScenario(\"fixed\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ewcUser1, ewcUser2 = getEWCResultByScenario(\"user\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ewcItem1, ewcItem2 = getEWCResultByScenario(\"item\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "naiveIncrease: {naiveIncrease}\n",
    "naivefixed: {naivefixed}\n",
    "naiveUser1: {naiveUser1}\n",
    "naiveUser2: {naiveUser2}\n",
    "naiveItem1\" {naiveItem1}\n",
    "naiveItem2\" {naiveItem2}\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "ewcIncrease: {ewcIncrease}\n",
    "ewcfixed: {ewcfixed}\n",
    "ewcUser1: {ewcUser1}\n",
    "ewcUser2: {ewcUser2}\n",
    "ewcItem1\" {ewcItem1}\n",
    "ewcItem2\" {ewcItem2}\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "{ewcIncrease-naiveIncrease}\n",
    "{ewcfixed-naivefixed}\n",
    "{ewcUser1-naiveUser1}\n",
    "{ewcUser2-naiveUser2}\n",
    "{ewcItem1-naiveItem1}\n",
    "{ewcItem2-naiveItem2}\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
